{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 10 and 11 Assignment - DATASCI200 Introduction to Data Science Programming, UC Berkeley MIDS\n",
    "\n",
    "Write code in this Jupyter Notebook to solve the following problems. Please upload this **Notebook** with your solutions to your GitHub repository and provide a link in the last question in gradescope. \n",
    "\n",
    "Assignment due date: 11:59PM PT the night before the Week 12 Live Session. Do **NOT** push/upload the data file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Explore and glean insights from a real dataset using pandas\n",
    "- Practice using pandas for exploratory analysis, information gathering, and discovery\n",
    "- Practice cleaning data and answering questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Guidelines:\n",
    "\n",
    "- This is a **real** dataset and so it may contain errors and other pecularities to work through\n",
    "- This dataset is ~218mb, which will take some time to load (and probably won't load in Google Sheets or Excel)\n",
    "- If you make assumptions, annotate them in your responses\n",
    "- While there is one code/markdown cell positioned after each question as a placeholder, some of your code/responses may require multiple cells\n",
    "- Double-click the markdown cells that say for example **1a answer here:** to enter your written answers. If you need more cells for your written answers, make them markdown cells (rather than code cells)\n",
    "- This homework assignment is not autograded because of the variety of responses one could give. \n",
    "  - Please upload this notebook to the autograder page and the TAs will manually grade it. \n",
    "  - Ensure that each cell is run and outputs your answer for ease of grading! \n",
    "  - Highly suggest to do a `restart & run all` before uploading your code to ensure everything runs and outputs correctly.\n",
    "  - Answers without code (or code that runs) will be given 0 points.\n",
    "- **This is meant to simulate real world data so you will have to do some external research to determine what some of the answers are!** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "You are to analyze campaign contributions to the 2016 U.S. presidential primary races made in California. Use the csv file located here: https://drive.google.com/file/d/1Lgg-PwXQ6TQLDowd6XyBxZw5g1NGWPjB/view?usp=sharing. You should download and save this file in the same folder as this notebook is stored.  This file originally came from the U.S. Federal Election Commission (https://www.fec.gov/).\n",
    "\n",
    "**DO NOT PUSH THIS FILE TO YOUR GITHUB REPO!**\n",
    "\n",
    "- Best practice is to not have DATA files in your code repo. As shown below, the default load is outside of the folder this notebook is in. If you change the folder where the file is stored please update the first cell!\n",
    "- If you do accidentally push the file to your github repo - follow the directions here to fix it: https://docs.google.com/document/d/15Irgb5V5G7pKPWgAerH7FPMpKeQRunbNflaW-hR2hTA/edit?usp=sharing\n",
    "\n",
    "Documentation for this data can be found here: https://drive.google.com/file/d/11o_SByceenv0NgNMstM-dxC1jL7I9fHL/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Questions\n",
    "\n",
    "You are working for a California state-wide election campaign. Your boss wants you to examine historic 2016 election contribution data to see what zipcodes are more supportive of fundraising for your candidate. \n",
    "\n",
    "Your boss asks you to filter out some of the records:\n",
    "- Only use primary 2016 contribution data (more like how your race is).\n",
    "- Concentrate on Bernie Sanders as a candidate (most a like your candidate)\n",
    "\n",
    "The questions your boss wants answered is:\n",
    "- Which zipcode (5-digit zipcode) had the highest count of contributions and the most dollar amount?\n",
    "- What day(s) of the month do most people donate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run the cell below as it will load the data into a pandas dataframe named `contrib`. Note that a custom date parser is defined to speed up loading. If Python were to guess the date format, it would take even longer to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'contb_receipt_dt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m file_id\u001b[39m=\u001b[39murl\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n\u001b[1;32m     16\u001b[0m dwn_url\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://drive.google.com/uc?id=\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m file_id\n\u001b[0;32m---> 17\u001b[0m contrib \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(dwn_url,low_memory\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, index_col\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, parse_dates\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39mcontb_receipt_dt\u001b[39;49m\u001b[39m'\u001b[39;49m], date_format\u001b[39m=\u001b[39;49md)\n\u001b[1;32m     19\u001b[0m \u001b[39m# Note - for now, it is okay to ignore the warning about mixed types. \u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1679\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1676\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1678\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1679\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1680\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1681\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:161\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_usecols_names(\n\u001b[1;32m    156\u001b[0m             usecols,\n\u001b[1;32m    157\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnames,  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    158\u001b[0m         )\n\u001b[1;32m    160\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_parse_dates_presence(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnames)  \u001b[39m# type: ignore[has-type]\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_noconvert_columns()\n\u001b[1;32m    164\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/parsers/base_parser.py:229\u001b[0m, in \u001b[0;36mParserBase._validate_parse_dates_presence\u001b[0;34m(self, columns)\u001b[0m\n\u001b[1;32m    219\u001b[0m missing_cols \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m    220\u001b[0m     \u001b[39msorted\u001b[39m(\n\u001b[1;32m    221\u001b[0m         {\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    226\u001b[0m     )\n\u001b[1;32m    227\u001b[0m )\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m missing_cols:\n\u001b[0;32m--> 229\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    230\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing column provided to \u001b[39m\u001b[39m'\u001b[39m\u001b[39mparse_dates\u001b[39m\u001b[39m'\u001b[39m\u001b[39m: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmissing_cols\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m     )\n\u001b[1;32m    232\u001b[0m \u001b[39m# Convert positions to actual column names\u001b[39;00m\n\u001b[1;32m    233\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[1;32m    234\u001b[0m     col \u001b[39mif\u001b[39;00m (\u001b[39misinstance\u001b[39m(col, \u001b[39mstr\u001b[39m) \u001b[39mor\u001b[39;00m col \u001b[39min\u001b[39;00m columns) \u001b[39melse\u001b[39;00m columns[col]\n\u001b[1;32m    235\u001b[0m     \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m cols_needed\n\u001b[1;32m    236\u001b[0m ]\n",
      "\u001b[0;31mValueError\u001b[0m: Missing column provided to 'parse_dates': 'contb_receipt_dt'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# These commands below set some options for pandas and to have matplotlib show the charts in the notebook\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "# Define a date parser to pass to read_csv\n",
    "d = lambda x: datetime.strptime(x, '%d-%b-%y')\n",
    "\n",
    "# Load the data\n",
    "# We have this defaulted to the folder OUTSIDE of your repo - please change it as needed\n",
    "url='https://drive.google.com/file/d/1Lgg-PwXQ6TQLDowd6XyBxZw5g1NGWPjB/view?usp=sharing'\n",
    "file_id=url.split('/')[-2]\n",
    "dwn_url='https://drive.google.com/uc?id=' + file_id\n",
    "contrib = pd.read_csv(dwn_url,low_memory=False, index_col=False, parse_dates=['contb_receipt_dt'], date_format=d)\n",
    "\n",
    "# Note - for now, it is okay to ignore the warning about mixed types. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1. Initial Data Checks (50 points)\n",
    "\n",
    "First we will take a preliminary look at the data to check that it was loaded correctly and contains the info we need.\n",
    "\n",
    "The questions to answer at the end of this section:\n",
    "- Do we have the correct # of columns and rows. \n",
    "- Do the records contain data for the questions we want to answer \n",
    "- What columns are important? \n",
    "- What columns can be dropped?\n",
    "- What are the data problems?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1a.** Print the *shape* of the data. Does this match the expectation? (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9f7a7938e43b14d3c7c49d6a278b0bb1",
     "grade": true,
     "grade_id": "cell-5d017805206f18b1",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 3)\n"
     ]
    }
   ],
   "source": [
    "# 1a YOUR CODE HERE\n",
    "print(contrib.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1a answer here:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e6a198453ec4b0171a064fef0bd7c678",
     "grade": true,
     "grade_id": "cell-3bc26919169bf4aa",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**1b.** Print a list of column names. Are all the columns included that are in the documentation? (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4fbf682f1c78b3614832c6f48ecd88c7",
     "grade": true,
     "grade_id": "cell-72bc97601b84f17d",
     "locked": false,
     "points": 5,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<!DOCTYPE html><html><head><title>Google Drive - Virus scan warning</title><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\"/><style nonce=\"8QjXom97vV3INv_SDll85Q\">.goog-inline-block{position:relative;display:-moz-inline-box;display:inline-block}* html .goog-inline-block{display:inline}*:first-child+html .goog-inline-block{display:inline}.goog-link-button{position:relative;color:#15c;text-decoration:underline;cursor:pointer}.goog-link-button-disabled{color:#ccc;text-decoration:none;cursor:default}body{color:#222;font:normal 13px/1.4 arial', 'sans-serif;margin:0}.grecaptcha-badge{visibility:hidden}.uc-main{padding-top:50px;text-align:center}#uc-dl-icon{display:inline-block;margin-top:16px;padding-right:1em;vertical-align:top}#uc-text{display:inline-block;max-width:68ex;text-align:left}.uc-error-caption', '.uc-warning-caption{color:#222;font-size:16px}#uc-download-link{text-decoration:none}.uc-name-size a{color:#15c;text-decoration:none}.uc-name-size a:visited{color:#61c;text-decoration:none}.uc-name-size a:active{color:#d14836;text-decoration:none}.uc-footer{color:#777;font-size:11px;padding-bottom:5ex;padding-top:5ex;text-align:center}.uc-footer a{color:#15c}.uc-footer a:visited{color:#61c}.uc-footer a:active{color:#d14836}.uc-footer-divider{color:#ccc;width:100%}sentinel{}</style><link rel=\"icon\" href=\"//ssl.gstatic.com/docs/doclist/images/drive_2022q3_32dp.png\"/></head><body><div class=\"uc-main\"><div id=\"uc-dl-icon\" class=\"image-container\"><div class=\"drive-sprite-aux-download-file\"></div></div><div id=\"uc-text\"><p class=\"uc-warning-caption\">Google Drive can\\'t scan this file for viruses.</p><p class=\"uc-warning-subcaption\"><span class=\"uc-name-size\"><a href=\"/open?id=1Lgg-PwXQ6TQLDowd6XyBxZw5g1NGWPjB\">P00000001-CA.csv</a> (213M)</span> is too large for Google to scan for viruses. Would you still like to download this file?</p><form id=\"download-form\" action=\"https://drive.google.com/uc?id=1Lgg-PwXQ6TQLDowd6XyBxZw5g1NGWPjB&amp;confirm=t&amp;uuid=9fa2d469-b30a-4c90-b21a-ad1e99b72de2\" method=\"post\"><input type=\"submit\" id=\"uc-download-link\" class=\"goog-inline-block jfk-button jfk-button-action\" value=\"Download anyway\"/></form></div></div><div class=\"uc-footer\"><hr class=\"uc-footer-divider\"></div></body></html>']\n"
     ]
    }
   ],
   "source": [
    "# 1b YOUR CODE HERE\n",
    "print(contrib.columns.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1b answer here:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1c** Print out the first five rows of the dataset. How do the columns `cand_id`, `cand_nm` and `contbr_st` look? (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [<!DOCTYPE html><html><head><title>Google Drive - Virus scan warning</title><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\"/><style nonce=\"8QjXom97vV3INv_SDll85Q\">.goog-inline-block{position:relative;display:-moz-inline-box;display:inline-block}* html .goog-inline-block{display:inline}*:first-child+html .goog-inline-block{display:inline}.goog-link-button{position:relative;color:#15c;text-decoration:underline;cursor:pointer}.goog-link-button-disabled{color:#ccc;text-decoration:none;cursor:default}body{color:#222;font:normal 13px/1.4 arial, sans-serif;margin:0}.grecaptcha-badge{visibility:hidden}.uc-main{padding-top:50px;text-align:center}#uc-dl-icon{display:inline-block;margin-top:16px;padding-right:1em;vertical-align:top}#uc-text{display:inline-block;max-width:68ex;text-align:left}.uc-error-caption, .uc-warning-caption{color:#222;font-size:16px}#uc-download-link{text-decoration:none}.uc-name-size a{color:#15c;text-decoration:none}.uc-name-size a:visited{color:#61c;text-decoration:none}.uc-name-size a:active{color:#d14836;text-decoration:none}.uc-footer{color:#777;font-size:11px;padding-bottom:5ex;padding-top:5ex;text-align:center}.uc-footer a{color:#15c}.uc-footer a:visited{color:#61c}.uc-footer a:active{color:#d14836}.uc-footer-divider{color:#ccc;width:100%}sentinel{}</style><link rel=\"icon\" href=\"//ssl.gstatic.com/docs/doclist/images/drive_2022q3_32dp.png\"/></head><body><div class=\"uc-main\"><div id=\"uc-dl-icon\" class=\"image-container\"><div class=\"drive-sprite-aux-download-file\"></div></div><div id=\"uc-text\"><p class=\"uc-warning-caption\">Google Drive can't scan this file for viruses.</p><p class=\"uc-warning-subcaption\"><span class=\"uc-name-size\"><a href=\"/open?id=1Lgg-PwXQ6TQLDowd6XyBxZw5g1NGWPjB\">P00000001-CA.csv</a> (213M)</span> is too large for Google to scan for viruses. Would you still like to download this file?</p><form id=\"download-form\" action=\"https://drive.google.com/uc?id=1Lgg-PwXQ6TQLDowd6XyBxZw5g1NGWPjB&amp;confirm=t&amp;uuid=9fa2d469-b30a-4c90-b21a-ad1e99b72de2\" method=\"post\"><input type=\"submit\" id=\"uc-download-link\" class=\"goog-inline-block jfk-button jfk-button-action\" value=\"Download anyway\"/></form></div></div><div class=\"uc-footer\"><hr class=\"uc-footer-divider\"></div></body></html>]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 1c YOUR CODE HERE\n",
    "print(contrib.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1c answer here:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "0ec29a2cabd52709322d1cfd650babe7",
     "grade": true,
     "grade_id": "cell-23b51536d24c1645",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**1d.** Print out the values for the column `election_tp`. In your own words, based on the documentation, what information does the `election_tp` variable contain? Do the values in the column match the documentation? (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1d YOUR CODE HERE\n",
    "print(contrib['election_tp'].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "cfa64002e64474584dc1442b5a39b460",
     "grade": true,
     "grade_id": "cell-8a320c2ff7c24d98",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "- **1d answer here:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "442b24601da06376c43cbe6ef5c5348a",
     "grade": true,
     "grade_id": "cell-6a453219105384dd",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**1e.** Print out the datatypes for all of the columns. What are the datatypes for the `contbr_zip`, `contb_receipt_amt`, `contb_receipt_dt`? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c5a1b7f30648cced7269ccb9b1532bd6",
     "grade": true,
     "grade_id": "cell-90c49bd6471a3dc9",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1e YOUR CODE HERE\n",
    "print(contrib.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "60d3e303837e9603de5b96e32af7d806",
     "grade": true,
     "grade_id": "cell-447dc63eff8ebc5f",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "- **1e answer here:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "20a71229316bf24a2ce62c52f72d8142",
     "grade": true,
     "grade_id": "cell-963603c5ed346a99",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**1f.** What columns have the most non-nulls?  Would you recommend to drop any columns based on the number of nulls? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "426b589a9d6457f38381eb1c77678d4f",
     "grade": true,
     "grade_id": "cell-b6fc3f7c906c95a2",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 1f YOUR CODE HERE\n",
    "print(contrib.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "81ebf2a2f96961b4464f6c35d2143427",
     "grade": true,
     "grade_id": "cell-bea2cf7a6fff8565",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "- **1f answer here:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1g.** A column we know that we want to use is the cand_nm column.  From the documentation each candidate is a unique candidate id also. Check data quality of `cand_id` column to see if it matches `cand_nm` column. Specifically check to ensure our targetted candidate 'Bernard Sanders' always has the same cand_id throughout. Any issues with `cand_nm` matching `cand_id`? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1g YOUR CODE HERE\n",
    "#print(contrib.groupby(['cand_id', 'cand_nm']).ngroups)\n",
    "print(pd.unique(contrib[['cand_id', 'cand_nm']].values.ravel()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1g answer here:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1h.** Another area to check is to make sure all of the records are from California. Check the `contbr_st` column - are there any records outside of California based on `contbr_st`? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1h YOUR CODE HERE\n",
    "print(contrib['contbr_st'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1h answer here:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1i.** The next column to check for the analysis is the `tran_id` column. This column could be the primary key so look for duplicates. How many duplicate entries are there? Any pattern for why are there duplicate entries? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1i YOUR CODE HERE\n",
    "print(contrib.tran_id.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1i answer here:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1j.** Another column to check is the `contb_receipt_amt` that shows the donation amounts. How many negative donations are included? What do negative donations mean? Please show at least pull a few rows to look at the records with negative donations. Do these records match with the expectation of why a negative donation would happen? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1j YOUR CODE HERE\n",
    "print(contrib.fillna(0).query('contb_receipt_amt < 0'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1j answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1k.** One more column to look at is the date of donation column. Are there any dates outside of the primary period (defined as 1 Jan 2014 to 7 June 2016)? Are the dates well-formatted for our analysis? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1k YOUR CODE HERE\n",
    "start_date = '2014-01-01'\n",
    "end_date   = '2016-06-07'\n",
    "contrib3 = contrib.query('contb_receipt_dt < @start_date and contb_receipt_dt > @end_date')\n",
    "print(contrib3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **1k answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "bffd2778d22127102347386bfb6f5b20",
     "grade": true,
     "grade_id": "cell-4ad1da24176f0450",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**1l.** Finally, answer the initial questions in the cells below (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1l.1** Do we have the correct # of columns and rows.\n",
    "\n",
    "- **1l.1 answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1l.2** Do the records contain data for the questions we want to answer?\n",
    "\n",
    "- **1l.2 answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1l.3** What columns are important?\n",
    "\n",
    "- **1l.3 answer here:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1l.4** What columns can be dropped?\n",
    "\n",
    "- **1l.4 answer here:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1l.5** What are the data problems?\n",
    "\n",
    "- **1l.5 answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1l.6** List any assumptions so far:\n",
    "\n",
    "- **1l.6 answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "14c2855e3d59f0da6b1afd5cf0da2da8",
     "grade": true,
     "grade_id": "cell-fd840cdd19d2bd2a",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "***\n",
    "## 2. Data filtering and data quality fixes (30 points)\n",
    "\n",
    "Now that we have a basic understanding of the data, let's filter out the records we don't need and fix the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2a.** From the dataset filter out (remove) any election_tp not in the primary election. Print/show the shape of the dataframe after the filtering is complete. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "43ce3d15cee7ab73f53fd8f054c9826c",
     "grade": true,
     "grade_id": "cell-dce8d3107c1463ca",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2a YOUR CODE HERE\n",
    "df7 = contrib[contrib.election_tp.str[0] != 'P']\n",
    "print(df7.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a5f4e6df0f32e24c492a9589ec87fef6",
     "grade": true,
     "grade_id": "cell-9e3f68b21dac8e10",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**2b.** From the dataset filter out (remove) any candidate that is not Bernie Sanders. Print/show the shape of the dataframe after the filtering is complete. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "4f1a9e7ee0ded9d2b5af5777cb85e505",
     "grade": true,
     "grade_id": "cell-c14fbed9d72d54e3",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# 2b YOUR CODE HERE\n",
    "list_values = [\"Bernie Sanders\"]\n",
    "df6 = contrib[~contrib['cand_nm'].isin(list_values)]\n",
    "print(df6.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2c.** The `contbr_zip` column is not formatted well for our analysis. Make a new zipcode column that is the five-digit zipcodes. Filter out any records outside of California based on the zipcode. Print/show the shape of the dataframe after the filtering is complete. (10 points).\n",
    "\n",
    "- You will have to research what the valid 5-digit zipcodes for California are!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2c YOUR CODE HERE\n",
    "df8 = contrib\n",
    "df8['contbr_zip_5'] = pd.to_numeric(df8['contbr_zip'].str.slice(0,5), errors='coerce')\n",
    "df8 = df8.query('contbr_zip_5 >= 90001 and contbr_zip_5 <= 96162') # This range is for CA Zipcodes\n",
    "print(df8.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2d.** The receipt amount column has negative donations. After talking with your team, a decision was made that the best course of action is to remove these negative values so that the donation count and amount is more accurate. Print/show the shape of the dataframe after the filtering is complete. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2d YOUR CODE HERE\n",
    "df7 = contrib.query('contb_receipt_amt < 0')\n",
    "print(df7.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2e.** From the dataset drop any columns that won't be used in the analysis. Print/show the shape of the dataframe after the dropping is complete. What columns did you drop and why? (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2e YOUR CODE HERE\n",
    "# contbr_employer     157902\n",
    "#receipt_desc         1110614\n",
    "df9 = contrib.drop(['contbr_employer', 'receipt_desc','memo_cd','memo_descr'], axis=1)\n",
    "print(df9.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2e answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2f.** List any assumptions that you made up to this point:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **2f answer here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "6dc1481a003cdd752c5edfa9ac400879",
     "grade": true,
     "grade_id": "cell-f7a01ce9c5b10ac7",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "***\n",
    "## 3. Answering the questions (20 points)\n",
    "\n",
    "Now that the data is cleaned and filterd - let's answer the two questions from your boss!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "010f5de5f6af4c7f830d1cf7a81bbc0f",
     "grade": true,
     "grade_id": "cell-5617179133b06d0c",
     "locked": false,
     "points": 0,
     "schema_version": 1,
     "solution": true
    }
   },
   "source": [
    "**3a.** Which zipcode had the highest count of contributions and the most dollar amount? (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3a YOUR CODE HERE\n",
    "\n",
    "df22=contrib.groupby(['contbr_zip'])['contb_receipt_amt'].sum().sort_values(ascending=False)\n",
    "print(df22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3a answer here:** \n",
    "#92067 Zip code has highest donation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3b.** What day(s) of the month do most people donate? (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3b YOUR CODE HERE\n",
    "\n",
    "df23=contrib.groupby(['contb_receipt_dt'])['contb_receipt_amt'].sum().sort_values(ascending=False)\n",
    "print(df23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **3b answer here:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Last day of the month are getting maximum contributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you have feedback for this homework, please submit it using the link below:\n",
    "\n",
    "http://goo.gl/forms/74yCiQTf6k"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
